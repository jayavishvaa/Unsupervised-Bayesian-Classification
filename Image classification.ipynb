{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy.linalg as lg\n",
    "import math\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "df_ls = pd.read_csv(\"Linearly Seperable/trian.txt\", delimiter=(\",\"), header = None)\n",
    "df_ls_dev = pd.read_csv(\"Linearly Seperable/dev.txt\", delimiter=(\",\"), header = None)\n",
    "\n",
    "df_nls = pd.read_csv(\"Non Linearly Seperable/trian.txt\", delimiter=(\",\"), header = None)\n",
    "df_nls_dev = pd.read_csv(\"Non Linearly Seperable/dev.txt\", delimiter=(\",\"), header = None)\n",
    "\n",
    "df_real = pd.read_csv(\"Real Data/trian.txt\", delimiter=(\",\"), header = None)\n",
    "df_real_dev = pd.read_csv(\"Real Data/dev.txt\", delimiter=(\",\"), header = None)\n",
    "\n",
    "\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "Essential Functions\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "def multivariate_gaussian(x,mu,C):\n",
    "    N = x.size\n",
    "    \n",
    "    return((2*np.pi)**(-N/2)*(lg.det(C)**(-1/2))*(np.exp(-.5*(x-mu).T@lg.inv(C)@(x-mu))))\n",
    "\n",
    "def grid_distribution(X1,X2,mu,C):\n",
    "    Z = np.zeros(X1.shape)\n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            x = np.array([X1[i,j],X2[i,j]]).reshape(2,1)\n",
    "            Z[i,j] = multivariate_gaussian(x, mu, C)\n",
    "    return Z\n",
    "\n",
    "def mle_estimates(x,y):\n",
    "    \n",
    "    classes = sorted(list(np.unique(y)))\n",
    "    \n",
    "    pi = []\n",
    "    mu = []\n",
    "    var = []\n",
    "    \n",
    "    for c in classes:\n",
    "        \n",
    "        indices = np.where(np.isin(y,c))\n",
    "        x_slice = x[indices]\n",
    "        \n",
    "        n = float(len(x_slice))\n",
    "        \n",
    "        pi.append(n/float(len(x)))\n",
    "        \n",
    "        mu_temp = (np.sum(x_slice,axis=0) / n).reshape(-1,1)\n",
    "        \n",
    "        mu.append(mu_temp)\n",
    "        \n",
    "        def compute_cov(row,mean):\n",
    "\n",
    "            return(row.reshape(-1,1) - mean).dot((row.reshape(-1,1) - mean).T)\n",
    "\n",
    "\t\t# do a list comprehension to sum over individual variances\n",
    "\t\t# to get a variance vector \n",
    "        var_temp = (1./(len(x_slice) - len(classes))) * (sum([compute_cov(row,mu_temp) for row in x_slice]))\n",
    "\n",
    "        var.append(var_temp)        \n",
    "    \n",
    "    return (classes, pi, mu, var)\n",
    "\n",
    "def get_colors(Z1,Z2,Z3):\n",
    "    colors = np.zeros_like(Z1, dtype=object)\n",
    "\n",
    "    for i in range(len(Z1)):\n",
    "      for j in range(len(Z1)):\n",
    "        if Z1[i,j] != 0:\n",
    "            colors[i,j] = 'Red'\n",
    "        elif Z2[i,j] != 0:\n",
    "            colors[i,j] = 'Blue'\n",
    "        elif Z3[i,j] != 0:\n",
    "            colors[i,j] = 'Green'\n",
    "        else:\n",
    "            colors[i,j] = 'Black'\n",
    "\n",
    "    return colors\n",
    "\n",
    "def plot_distribution(m_estimates, elevation = 20, azim = -15, title = 'Multivariate Distribution', zlow = -0.1, zhigh = 0.1, x1low = -10, x1high = 20, x2low = -10, x2high = 20, zbound = 0.0005):\n",
    "    x1 = np.linspace(x1low,x1high,100)\n",
    "    x2 = np.linspace(x2low,x2high,100)\n",
    "    X1,X2 = np.meshgrid(x1,x2)\n",
    "        \n",
    "    Z1 = grid_distribution(X1,X2,m_estimates[2][0],m_estimates[3][0])\n",
    "    Z2 = grid_distribution(X1,X2,m_estimates[2][1],m_estimates[3][1])\n",
    "    Z3 = grid_distribution(X1,X2,m_estimates[2][2],m_estimates[3][2])\n",
    "    Z1[Z1<zbound] = 0\n",
    "    Z2[Z2<zbound] = 0\n",
    "    Z3[Z3<zbound] = 0\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize = (10,8))\n",
    "    fig.tight_layout()\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax.set_zlim(zlow,zhigh)\n",
    "    ax.view_init(elevation, azim)\n",
    "\n",
    "    ax.plot_surface(X1, X2, Z1+Z2+Z3, facecolors = get_colors(Z1,Z2,Z3), rstride=3, cstride=3, linewidth=1)\n",
    "\n",
    "    ax.contour(X1,X2,Z1,zdir = 'z', offset = zlow)\n",
    "    ax.contour(X1,X2,Z2,zdir = 'z', offset = zlow)\n",
    "    ax.contour(X1,X2,Z3,zdir = 'z', offset = zlow)\n",
    "    \n",
    "    ax.set_xlabel(\"X1\")\n",
    "    ax.set_ylabel('X2')\n",
    "    ax.set_zlabel(\"Probability\")\n",
    "    ax.zaxis.labelpad = 10\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_eigen(m_estimates, title = 'Multivariate Distribution', x1low = -10, x1high = 20, x2low = -10, x2high = 20):\n",
    "    x1 = np.linspace(x1low,x1high,100)\n",
    "    x2 = np.linspace(x2low,x2high,100)\n",
    "    X1,X2 = np.meshgrid(x1,x2)\n",
    "        \n",
    "    Z1 = grid_distribution(X1,X2,m_estimates[2][0],m_estimates[3][0])\n",
    "    Z2 = grid_distribution(X1,X2,m_estimates[2][1],m_estimates[3][1])\n",
    "    Z3 = grid_distribution(X1,X2,m_estimates[2][2],m_estimates[3][2])\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize = (10,8))\n",
    "    fig.tight_layout()\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    eigen_values, eigen_vectors = lg.eig(m_estimates[3][0])\n",
    "    eig_vec1 = eigen_vectors[:,0]\n",
    "    eig_vec2 = eigen_vectors[:,1]\n",
    "    origin = m_estimates[2][0]\n",
    "    ax.contour(X1,X2,Z1)\n",
    "    ax.quiver(*origin, *eig_vec1, color=['r'], scale = 5)\n",
    "    ax.quiver(*origin, *eig_vec2, color=['b'], scale = 5)\n",
    "    \n",
    "    eigen_values, eigen_vectors = lg.eig(m_estimates[3][1])\n",
    "    eig_vec1 = eigen_vectors[:,0]\n",
    "    eig_vec2 = eigen_vectors[:,1]\n",
    "    origin = m_estimates[2][1]\n",
    "    ax.contour(X1,X2,Z2)\n",
    "    ax.quiver(*origin, *eig_vec1, color=['g'], scale = 5)\n",
    "    ax.quiver(*origin, *eig_vec2, color=['c'], scale = 5)\n",
    "    \n",
    "    \n",
    "    eigen_values, eigen_vectors = lg.eig(m_estimates[3][2])\n",
    "    eig_vec1 = eigen_vectors[:,0]\n",
    "    eig_vec2 = eigen_vectors[:,1]\n",
    "    origin = m_estimates[2][2]\n",
    "    ax.contour(X1,X2,Z3)\n",
    "    ax.quiver(*origin, *eig_vec1, color=['b'], scale = 5)\n",
    "    ax.quiver(*origin, *eig_vec2, color=['m'], scale = 5)\n",
    "    \n",
    "    \n",
    "    ax.set_xlabel(\"Dim 1\")\n",
    "    ax.set_ylabel('Dim 2')\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "def m_estimate_computer(x,y, case = 2):\n",
    "    \n",
    "    if case == 2:\n",
    "        return mle_estimates(x.to_numpy(),y.to_numpy())\n",
    "    \n",
    "    if case == 1:\n",
    "        temp_estimates = mle_estimates(x.to_numpy(),y.to_numpy())        \n",
    "        temp_var = np.cov(x, rowvar=0)\n",
    "        temp_estimates = list(temp_estimates)\n",
    "        temp_estimates.append(temp_var)\n",
    "        temp_estimates = tuple(temp_estimates)\n",
    "        \n",
    "        return temp_estimates\n",
    "    \n",
    "    if case == 3:\n",
    "        temp_estimates = mle_estimates(x.to_numpy(),y.to_numpy())  \n",
    "        temp_var = np.sum(np.diag(np.cov(x,rowvar=0)))/len(temp_estimates[0])\n",
    "        temp_estimates = list(temp_estimates)\n",
    "        temp_estimates.append(temp_var)\n",
    "        temp_estimates = tuple(temp_estimates)\n",
    "        return temp_estimates\n",
    "    \n",
    "    if case == 4:\n",
    "        temp_estimates = mle_estimates(x.to_numpy(),y.to_numpy())        \n",
    "        temp_var = np.diag(np.diag(np.cov(x, rowvar=0)))\n",
    "        temp_estimates = list(temp_estimates)\n",
    "        temp_estimates.append(temp_var)\n",
    "        temp_estimates = tuple(temp_estimates)\n",
    "        \n",
    "        return temp_estimates\n",
    "    \n",
    "    if case == 5:\n",
    "        temp_estimates = mle_estimates(x.to_numpy(),y.to_numpy())        \n",
    "        \n",
    "        for i in range(len(temp_estimates[0])):\n",
    "            temp_estimates[3][i] = np.diag(np.diag(temp_estimates[3][i]))\n",
    "        return temp_estimates\n",
    "        \n",
    "    \n",
    "def bayes_prediction_case_1(X, m_estimates):\n",
    "    \n",
    "    bayes_probabilities = []\n",
    "    \n",
    "    sigma = m_estimates[4] \n",
    "    \n",
    "    sigma_inv = lg.inv(sigma)\n",
    "    \n",
    "    for i in range(len(m_estimates[0])):\n",
    "        \n",
    "        bayes_probs = []\n",
    "        \n",
    "        pi = m_estimates[1][i]\n",
    "        \n",
    "        mu = m_estimates[2][i]\n",
    "        \n",
    "        for x in X:\n",
    "            \n",
    "            x = x.reshape(-1,1)\n",
    "            \n",
    "            wi = np.dot(sigma_inv, mu)\n",
    "            \n",
    "            wio = -(.5*lg.multi_dot([mu.T, sigma_inv, mu])) + np.log(pi)\n",
    "            \n",
    "            bayes_prob = np.dot(wi.T, x) + wio\n",
    "        \n",
    "            bayes_probs.append(bayes_prob)\n",
    "        \n",
    "        bayes_probabilities.append(np.array(bayes_probs).reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    bayes_probabilities = np.concatenate(bayes_probabilities,axis=1)\n",
    "    \n",
    "    prediction_class_indices = np.argmax(bayes_probabilities, axis = 1)\n",
    "    \n",
    "    predictions = np.array([m_estimates[0][i] for i in prediction_class_indices])\n",
    "    \n",
    "    return (bayes_probabilities, predictions)\n",
    "\n",
    "\n",
    "def bayes_prediction_case_2(X, m_estimates):\n",
    "    \n",
    "    bayes_probabilities = []\n",
    "    \n",
    "    for i in range(len(m_estimates[0])):\n",
    "        \n",
    "        bayes_probs = []\n",
    "        \n",
    "        pi = m_estimates[1][i]\n",
    "        \n",
    "        mu = m_estimates[2][i]\n",
    "        \n",
    "        sigma = m_estimates[3][i]\n",
    "        \n",
    "        sigma_inv = lg.inv(sigma)\n",
    "        \n",
    "        for x in X:\n",
    "            \n",
    "            x = x.reshape(-1,1)\n",
    "            \n",
    "            bayes_prob = (-.5 * lg.multi_dot([(x-mu).T,(sigma_inv),(x-mu)])[0][0]) - (.5 * np.log(lg.det(sigma))) + np.log(pi)\n",
    "        \n",
    "            bayes_probs.append(bayes_prob)\n",
    "        \n",
    "        bayes_probabilities.append(np.array(bayes_probs).reshape(-1,1))\n",
    "    \n",
    "    bayes_probabilities = np.concatenate(bayes_probabilities,axis=1)\n",
    "    \n",
    "    prediction_class_indices = np.argmax(bayes_probabilities, axis = 1)\n",
    "    \n",
    "    predictions = np.array([m_estimates[0][i] for i in prediction_class_indices])\n",
    "    \n",
    "    return (bayes_probabilities, predictions)\n",
    "\n",
    "\n",
    "def bayes_prediction_case_3(X, m_estimates):\n",
    "    \n",
    "    bayes_probabilities = []\n",
    "    \n",
    "    var = m_estimates[4]\n",
    "    \n",
    "    for i in range(len(m_estimates[0])):\n",
    "        \n",
    "        bayes_probs = []\n",
    "        \n",
    "        pi = m_estimates[1][i]\n",
    "        \n",
    "        mu = m_estimates[2][i]\n",
    "    \n",
    "        \n",
    "        for x in X:\n",
    "            \n",
    "            x = x.reshape(-1,1)\n",
    "            \n",
    "            wi = mu/var\n",
    "            \n",
    "            bayes_prob = np.dot(wi.T, x) + np.log(pi) + (-1/(2*var))*np.dot(mu.T,mu)\n",
    "        \n",
    "            bayes_probs.append(bayes_prob)\n",
    "        \n",
    "        bayes_probabilities.append(np.array(bayes_probs).reshape(-1,1))\n",
    "    \n",
    "    bayes_probabilities = np.concatenate(bayes_probabilities,axis=1)\n",
    "    \n",
    "    prediction_class_indices = np.argmax(bayes_probabilities, axis = 1)\n",
    "    \n",
    "    predictions = np.array([m_estimates[0][i] for i in prediction_class_indices])\n",
    "    \n",
    "    return (bayes_probabilities, predictions)\n",
    "\n",
    "\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "Experimentation and Results\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "\n",
    "'''''''''''''''''\n",
    "Preperation of Data\n",
    "'''''''''''''''''\n",
    "\n",
    "x_ls = df_ls.loc[:,:1]\n",
    "y_ls = df_ls.loc[:, 2]\n",
    "\n",
    "x_ls_dev = df_ls_dev.loc[:,:1]\n",
    "y_ls_dev = df_ls_dev.loc[:, 2]\n",
    "\n",
    "x_nls = df_nls.loc[:,:1]\n",
    "y_nls = df_nls.loc[:, 2]\n",
    "\n",
    "x_nls_dev = df_nls_dev.loc[:,:1]\n",
    "y_nls_dev = df_nls_dev.loc[:, 2]\n",
    "\n",
    "\n",
    "x_real = df_real.loc[:,:1]\n",
    "y_real = df_real.loc[:, 2]\n",
    "\n",
    "x_real_dev = df_real_dev.loc[:,:1]\n",
    "y_real_dev = df_real_dev.loc[:, 2]\n",
    "\n",
    "\n",
    "'''''''''''''''''\n",
    "Multivariate Plots for each data set (Only Train Sets)\n",
    "'''''''''''''''''\n",
    "\n",
    "m_estimates_ls = m_estimate_computer(x_ls,y_ls, case = 2)\n",
    "m_estimates_nls = m_estimate_computer(x_nls,y_nls, case = 2)\n",
    "m_estimates_real = m_estimate_computer(x_real,y_real, case = 2)\n",
    "\n",
    "plot_distribution(m_estimates_ls, title = 'Multivariate Distribution for Linearly seperable Data')\n",
    "plot_distribution(m_estimates_nls, title = 'Multivariate Distribution for Linearly Non seperable Data', x1low = math.floor(x_nls.min()[0]), x1high = math.ceil(x_nls.max()[0]), x2low = math.floor(x_nls.min()[1]), x2high = math.ceil(x_nls.max()[1]))\n",
    "plot_distribution(m_estimates_real, title = 'Multivariate Distribution for Real Data', x1low = math.floor(x_real.min()[0]), x1high = math.ceil(x_real.max()[0]), x2low = math.floor(x_real.min()[1]), x2high = math.ceil(x_real.max()[1]), zbound = 1e-7, zlow = -1e-5, zhigh = 1e-5)\n",
    "\n",
    "\n",
    "plot_eigen(m_estimates_ls, title = 'Constant Density Curve and Eigen Vectors for Linearly seperable Data', x1low = -5, x1high = 18, x2low = -2, x2high = 20)\n",
    "plot_eigen(m_estimates_nls, title = 'Constant Density Curve and Eigen Vectors for Linearly Non seperable Data', x1low = 15, x1high = 50, x2low = math.floor(x_nls.min()[1]), x2high = math.ceil(x_nls.max()[1]))\n",
    "plot_eigen(m_estimates_real, title = 'Constant Density Curve and Eigen Vectors for Real Data', x1low = 150, x1high = 950, x2low = 350, x2high = 2500)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''''''''''''''''\n",
    "Decision Surfaces and Confusion Matrices\n",
    "'''''''''''''''''\n",
    "\n",
    "'''\n",
    "Case I: Bayes with Covariance Same for all Classes\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_decision_boundary_local(df,x,y, title = 'Case 1'):\n",
    "    X1 = np.linspace(math.floor(x.min()[0]), math.ceil(x.max()[0]), 100)\n",
    "    X2 = np.linspace(math.floor(x.min()[1]), math.ceil(x.max()[1]), 100)\n",
    "    X1, X2 = np.meshgrid(X1, X2)\n",
    "    \n",
    "    \n",
    "    g = sns.FacetGrid(df, hue=2 , height=8, palette = 'colorblind').map(plt.scatter,0,1).add_legend()\n",
    "    \n",
    "    g._legend.set_title(\"Class\")\n",
    "    \n",
    "    ax = g.ax\n",
    "    \n",
    "    Z = np.zeros(X1.shape)\n",
    "    \n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            x_temp = np.array([[X1[i,j],X2[i,j]]])\n",
    "            Z[i,j] = bayes_prediction_case_1(x_temp,  m_estimate_computer(x,y, case = 1))[1][0]\n",
    "            \n",
    "    \n",
    "            \n",
    "    ax.contourf( X1, X2, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "    ax.contour( X1, X2, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "            \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "plot_decision_boundary_local(df_ls, x_ls, y_ls, title = \"Decision Surface for Case 1 with Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_nls, x_nls, y_nls, title = \"Decision Surface for Case 1 with Non Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_real, x_real, y_real, title = \"Decision Surface for Case 1 with Real Data\")\n",
    "\n",
    "def plot_confusion_matrix_local(x_dev,y_dev,x_train,y_train, title = 'Confusion Matrix Case 1 with Linearly Seperable Data'):\n",
    "    predictions = bayes_prediction_case_1(x_dev.to_numpy(),  m_estimate_computer(x_train,y_train, case = 1))\n",
    "    \n",
    "    y_pred = predictions[1]\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_dev.to_numpy(), y_pred)\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    \n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt = '', cmap='Blues', cbar = False)\n",
    "\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('Actual Class');\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    ax.yaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix_local(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'Confusion Matrix Case 1 with Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'Confusion Matrix Case 1 with Non Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_real_dev, y_real_dev, x_real, y_real, title = 'Confusion Matrix Case 1 with Real Data')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Case II: Bayes with Covariance different for all Classes\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_decision_boundary_local(df,x,y, title = 'Case 2'):\n",
    "    X1 = np.linspace(math.floor(x.min()[0]), math.ceil(x.max()[0]), 100)\n",
    "    X2 = np.linspace(math.floor(x.min()[1]), math.ceil(x.max()[1]), 100)\n",
    "    X1, X2 = np.meshgrid(X1, X2)\n",
    "    \n",
    "    \n",
    "    g = sns.FacetGrid(df, hue=2 , height=8, palette = 'colorblind').map(plt.scatter,0,1).add_legend()\n",
    "    \n",
    "    g._legend.set_title(\"Class\")\n",
    "    \n",
    "    ax = g.ax\n",
    "    \n",
    "    Z = np.zeros(X1.shape)\n",
    "    \n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            x_temp = np.array([[X1[i,j],X2[i,j]]])\n",
    "            Z[i,j] = bayes_prediction_case_2(x_temp,  m_estimate_computer(x,y, case = 2))[1][0]\n",
    "            \n",
    "    \n",
    "            \n",
    "    ax.contourf( X1, X2, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "    ax.contour( X1, X2, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "            \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "plot_decision_boundary_local(df_ls, x_ls, y_ls, title = \"Decision Surface for Case 2 with Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_nls, x_nls, y_nls, title = \"Decision Surface for Case 2 with Non Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_real, x_real, y_real, title = \"Decision Surface for Case 2 with Real Data\")\n",
    "\n",
    "def plot_confusion_matrix_local(x_dev,y_dev,x_train,y_train, title = 'Confusion Matrix Case 2 with Linearly Seperable Data'):\n",
    "    predictions = bayes_prediction_case_2(x_dev.to_numpy(),  m_estimate_computer(x_train,y_train, case = 2))\n",
    "    \n",
    "    y_pred = predictions[1]\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_dev.to_numpy(), y_pred)\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    \n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt = '', cmap='Blues', cbar = False)\n",
    "\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('Actual Class');\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    ax.yaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix_local(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'Confusion Matrix Case 2 with Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'Confusion Matrix Case 2 with Non Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_real_dev, y_real_dev, x_real, y_real, title = 'Confusion Matrix Case 2 with Real Data')\n",
    "\n",
    "\n",
    "'''\n",
    "Case III: Bayes with Covariance sigma^2I\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_decision_boundary_local(df,x,y, title = 'Case 3'):\n",
    "    X1 = np.linspace(math.floor(x.min()[0]), math.ceil(x.max()[0]), 100)\n",
    "    X2 = np.linspace(math.floor(x.min()[1]), math.ceil(x.max()[1]), 100)\n",
    "    X1, X2 = np.meshgrid(X1, X2)\n",
    "    \n",
    "    \n",
    "    g = sns.FacetGrid(df, hue=2 , height=8, palette = 'colorblind').map(plt.scatter,0,1).add_legend()\n",
    "    \n",
    "    g._legend.set_title(\"Class\")\n",
    "    \n",
    "    ax = g.ax\n",
    "    \n",
    "    Z = np.zeros(X1.shape)\n",
    "    \n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            x_temp = np.array([[X1[i,j],X2[i,j]]])\n",
    "            Z[i,j] = bayes_prediction_case_3(x_temp,  m_estimate_computer(x,y, case = 3))[1][0]\n",
    "            \n",
    "    \n",
    "            \n",
    "    ax.contourf( X1, X2, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "    ax.contour( X1, X2, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "            \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "plot_decision_boundary_local(df_ls, x_ls, y_ls, title = \"Decision Surface for Case 3 with Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_nls, x_nls, y_nls, title = \"Decision Surface for Case 3 with Non Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_real, x_real, y_real, title = \"Decision Surface for Case 3 with Real Data\")\n",
    "\n",
    "def plot_confusion_matrix_local(x_dev,y_dev,x_train,y_train, title = 'Confusion Matrix Case 3 with Linearly Seperable Data'):\n",
    "    predictions = bayes_prediction_case_3(x_dev.to_numpy(),  m_estimate_computer(x_train,y_train, case = 3))\n",
    "    \n",
    "    y_pred = predictions[1]\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_dev.to_numpy(), y_pred)\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    \n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt = '', cmap='Blues', cbar = False)\n",
    "\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('Actual Class');\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    ax.yaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix_local(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'Confusion Matrix Case 3 with Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'Confusion Matrix Case 3 with Non Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_real_dev, y_real_dev, x_real, y_real, title = 'Confusion Matrix Case 3 with Real Data')\n",
    " \n",
    "\n",
    "'''\n",
    "Case IV: Naive Bayes with Covariance same for all Classes\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_decision_boundary_local(df,x,y, title = 'Case 4'):\n",
    "    X1 = np.linspace(math.floor(x.min()[0]), math.ceil(x.max()[0]), 100)\n",
    "    X2 = np.linspace(math.floor(x.min()[1]), math.ceil(x.max()[1]), 100)\n",
    "    X1, X2 = np.meshgrid(X1, X2)\n",
    "    \n",
    "    \n",
    "    g = sns.FacetGrid(df, hue=2 , height=8, palette = 'colorblind').map(plt.scatter,0,1).add_legend()\n",
    "    \n",
    "    g._legend.set_title(\"Class\")\n",
    "    \n",
    "    ax = g.ax\n",
    "    \n",
    "    Z = np.zeros(X1.shape)\n",
    "    \n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            x_temp = np.array([[X1[i,j],X2[i,j]]])\n",
    "            Z[i,j] = bayes_prediction_case_1(x_temp,  m_estimate_computer(x,y, case = 4))[1][0]\n",
    "            \n",
    "    \n",
    "            \n",
    "    ax.contourf( X1, X2, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "    ax.contour( X1, X2, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "            \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "plot_decision_boundary_local(df_ls, x_ls, y_ls, title = \"Decision Surface for Case 4 with Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_nls, x_nls, y_nls, title = \"Decision Surface for Case 4 with Non Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_real, x_real, y_real, title = \"Decision Surface for Case 4 with Real Data\")\n",
    "\n",
    "def plot_confusion_matrix_local(x_dev,y_dev,x_train,y_train, title = 'Confusion Matrix Case 4 with Linearly Seperable Data'):\n",
    "    predictions = bayes_prediction_case_1(x_dev.to_numpy(),  m_estimate_computer(x_train,y_train, case = 4))\n",
    "    \n",
    "    y_pred = predictions[1]\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_dev.to_numpy(), y_pred)\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    \n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt = '', cmap='Blues', cbar = False)\n",
    "\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('Actual Class');\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    ax.yaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix_local(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'Confusion Matrix Case 4 with Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'Confusion Matrix Case 4 with Non Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_real_dev, y_real_dev, x_real, y_real, title = 'Confusion Matrix Case 4 with Real Data')\n",
    " \n",
    "\n",
    "'''\n",
    "Case V: Naive Bayes with Covariance different for all Classes\n",
    "'''\n",
    "\n",
    "\n",
    "def plot_decision_boundary_local(df,x,y, title = 'Case 5'):\n",
    "    X1 = np.linspace(math.floor(x.min()[0]), math.ceil(x.max()[0]), 100)\n",
    "    X2 = np.linspace(math.floor(x.min()[1]), math.ceil(x.max()[1]), 100)\n",
    "    X1, X2 = np.meshgrid(X1, X2)\n",
    "    \n",
    "    \n",
    "    g = sns.FacetGrid(df, hue=2 , height=8, palette = 'colorblind').map(plt.scatter,0,1).add_legend()\n",
    "    \n",
    "    g._legend.set_title(\"Class\")\n",
    "    \n",
    "    ax = g.ax\n",
    "    \n",
    "    Z = np.zeros(X1.shape)\n",
    "    \n",
    "    for i in range(X1.shape[0]):\n",
    "        for j in range(X1.shape[1]):\n",
    "            x_temp = np.array([[X1[i,j],X2[i,j]]])\n",
    "            Z[i,j] = bayes_prediction_case_2(x_temp,  m_estimate_computer(x,y, case = 5))[1][0]\n",
    "            \n",
    "    \n",
    "            \n",
    "    ax.contourf( X1, X2, Z, 2, alpha = .1, colors = ('blue','green','red'))\n",
    "    ax.contour( X1, X2, Z, 2, alpha = 1, colors = ('blue','green','red'))\n",
    "            \n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.show()    \n",
    "    \n",
    "plot_decision_boundary_local(df_ls, x_ls, y_ls, title = \"Decision Surface for Case 5 with Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_nls, x_nls, y_nls, title = \"Decision Surface for Case 5 with Non Linearly Seperable Data\")\n",
    "plot_decision_boundary_local(df_real, x_real, y_real, title = \"Decision Surface for Case 5 with Real Data\")\n",
    "\n",
    "def plot_confusion_matrix_local(x_dev,y_dev,x_train,y_train, title = 'Confusion Matrix Case 5 with Linearly Seperable Data'):\n",
    "    predictions = bayes_prediction_case_2(x_dev.to_numpy(),  m_estimate_computer(x_train,y_train, case = 5))\n",
    "    \n",
    "    y_pred = predictions[1]\n",
    "    \n",
    "    cf_matrix = confusion_matrix(y_dev.to_numpy(), y_pred)\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cf_matrix.flatten()]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                      cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    labels = [f\"{v1}\\n{v2}\\n\" for v1, v2 in\n",
    "          zip(group_counts,group_percentages)]\n",
    "\n",
    "    labels = np.asarray(labels).reshape(3,3)\n",
    "    \n",
    "    ax = sns.heatmap(cf_matrix, annot=labels, fmt = '', cmap='Blues', cbar = False)\n",
    "\n",
    "    ax.set_title(title);\n",
    "    ax.set_xlabel('Predicted Class')\n",
    "    ax.set_ylabel('Actual Class');\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    ax.yaxis.set_ticklabels(['Clas 1','Class 2', 'Class 3'])\n",
    "    plt.show()\n",
    "    \n",
    "plot_confusion_matrix_local(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'Confusion Matrix Case 5 with Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'Confusion Matrix Case 5 with Non Linearly Seperable Data')\n",
    "plot_confusion_matrix_local(x_real_dev, y_real_dev, x_real, y_real, title = 'Confusion Matrix Case 5 with Real Data')\n",
    " \n",
    "\n",
    "'''''''''''''''''\n",
    "ROC and DET Curves\n",
    "'''''''''''''''''\n",
    "def roc_rates(scores, y_actual):\n",
    "    TPR = []\n",
    "    FPR = []\n",
    "    FNR = []\n",
    "    \n",
    "    for threshold in np.linspace(scores.max(), scores.min(), 100):\n",
    "        TP = FP = TN = FN = 0\n",
    "        for i in range(scores.shape[0]):\n",
    "            for j in range(scores.shape[1]):\n",
    "                if scores[i][j] >= threshold:\n",
    "                    if y_actual[i] == (j + 1):\n",
    "                        TP = TP + 1\n",
    "                    else: \n",
    "                        FP = FP + 1\n",
    "                else:\n",
    "                    if y_actual[i] == (j + 1):\n",
    "                        FN = FN + 1\n",
    "                    else: \n",
    "                        TN = TN + 1\n",
    "        FNR.append(FN/(FN+TP))\n",
    "        TPR.append(TP/(TP + FN))\n",
    "        FPR.append(FP/(FP + TN))\n",
    "    \n",
    "    return (TPR,FPR,FNR)\n",
    "\n",
    "def roc_plotter(x_dev,y_dev,x_train,y_train,title = 'ROC Plot for Linearly Seperable Data'):\n",
    "    scores_1 = bayes_prediction_case_1(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 1))[0]\n",
    "    scores_2 = bayes_prediction_case_2(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 2))[0]\n",
    "    scores_3 = bayes_prediction_case_3(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 3))[0]\n",
    "    scores_4 = bayes_prediction_case_1(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 4))[0]\n",
    "    scores_5 = bayes_prediction_case_2(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 5))[0]\n",
    "    \n",
    "    TPR1,FPR1,FNR1 = roc_rates(scores_1, y_dev)\n",
    "    plt.plot(FPR1,TPR1, label = 'Case 1')\n",
    "    TPR2,FPR2,FNR2 = roc_rates(scores_2, y_dev)\n",
    "    plt.plot(FPR2,TPR2, label = 'Case 2')\n",
    "    TPR3,FPR3,FNR3 = roc_rates(scores_3, y_dev)\n",
    "    plt.plot(FPR3,TPR3, label = 'Case 3')\n",
    "    TPR4,FPR4,FNR4 = roc_rates(scores_4, y_dev)\n",
    "    plt.plot(FPR4,TPR4, label = 'Case 4')\n",
    "    TPR5,FPR5,FNR5 = roc_rates(scores_5, y_dev)\n",
    "    plt.plot(FPR5,TPR5, label = 'Case 5')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"False Positivity Rate (FPR)\")\n",
    "    plt.ylabel(\"True Positivity Rate (TPR)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "roc_plotter(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'ROC Plot for Linearly Seperable Data')\n",
    "roc_plotter(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'ROC Plot for Non Linearly Seperable Data')\n",
    "roc_plotter(x_real_dev, y_real_dev, x_real, y_real, title = 'ROC Plot for Real Data')\n",
    "            \n",
    "def det_plotter(x_dev,y_dev,x_train,y_train,title = 'DET Plot for Linearly Seperable Data'):\n",
    "    scores_1 = bayes_prediction_case_1(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 1))[0]\n",
    "    scores_2 = bayes_prediction_case_2(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 2))[0]\n",
    "    scores_3 = bayes_prediction_case_3(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 3))[0]\n",
    "    scores_4 = bayes_prediction_case_1(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 4))[0]\n",
    "    scores_5 = bayes_prediction_case_2(x_dev.to_numpy(), m_estimate_computer(x_train, y_train, case = 5))[0]\n",
    "    \n",
    "    TPR1,FPR1,FNR1 = roc_rates(scores_1, y_dev)\n",
    "    plt.plot(FPR1,FNR1, label = 'Case 1')\n",
    "    TPR2,FPR2,FNR2 = roc_rates(scores_2, y_dev)\n",
    "    plt.plot(FPR2,FNR2, label = 'Case 2')\n",
    "    TPR3,FPR3,FNR3 = roc_rates(scores_3, y_dev)\n",
    "    plt.plot(FPR3,FNR3, label = 'Case 3')\n",
    "    TPR4,FPR4,FNR4 = roc_rates(scores_4, y_dev)\n",
    "    plt.plot(FPR4,FNR4, label = 'Case 4')\n",
    "    TPR5,FPR5,FNR5 = roc_rates(scores_5, y_dev)\n",
    "    plt.plot(FPR5,FNR5, label = 'Case 5')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"False Positivity Rate (FPR)\")\n",
    "    plt.ylabel(\"False Negativity Rate (FNR)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "det_plotter(x_ls_dev, y_ls_dev, x_ls, y_ls, title = 'DET Plot for Linearly Seperable Data')\n",
    "det_plotter(x_nls_dev, y_nls_dev, x_nls, y_nls, title = 'DET Plot for Non Linearly Seperable Data')\n",
    "det_plotter(x_real_dev, y_real_dev, x_real, y_real, title = 'DET Plot for Real Data')\n",
    "\n",
    "\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n",
    "--------------------------------------THE END--------------------------------------\n",
    "'''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
